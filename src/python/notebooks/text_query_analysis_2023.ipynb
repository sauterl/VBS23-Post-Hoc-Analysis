{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Processing text queries\n",
    "- code in this notebook predominantly analyze text queries submitted by participants to solve KIS tasks of VBS 2023\n",
    "- among others, this notebook can replicate the content of Table 2 and 3 as well as Figures 13-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# if in notebook folder, change directory to parent one\n",
    "import os\n",
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    os.chdir('..')\n",
    "import sys\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "from notebooks.utils import compute_user_penalty, get_team_values_df\n",
    "from common.load import load_competition_data, process_team_logs\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "unknownRankLimit = 1000\n",
    "unknownRankValue = 2000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import common data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = 'config_vbs2023.yaml'\n",
    "\n",
    "# load competition data from dres files and auxiliary data (FPSs, sequences)\n",
    "comp_data = load_competition_data(config)\n",
    "\n",
    "# load the preprocessed query data\n",
    "dataset = pd.read_pickle(comp_data[\"config\"][\"processed_logs_outdir\"] + '/text_query_dataset.pkl')\n",
    "\n",
    "# valid teams\n",
    "team_order = ['vibro', 'VISIONE',  'vitrivr-VR', 'CVHunter', 'Verge']\n",
    "#team_order = ['vibro', 'VISIONE', 'VIREO' 'vitrivr-VR', 'CVHunter', 'vitrivr', 'Verge']\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Creating auxiliary variables\n",
    "- Query length and volume of words per query\n",
    "- Maybe also store information whether the query is temporal? Only HTW and VISIONE have obviouse temporal queries\n",
    "- Define visual vs textual tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"task_type\"] = \"visual\"\n",
    "dataset.loc[dataset.task.str.contains(\"kis-t\"),\"task_type\"] = \"textual\"\n",
    "\n",
    "dataset[\"QT\"] = \"Other\"\n",
    "dataset.loc[dataset.is_joint_embedding_text_query, \"QT\"] = \"Text\"\n",
    "\n",
    "dataset[\"QueryLen\"] = -1\n",
    "dataset[\"QueryWords\"] = -1\n",
    "\n",
    "dataset.loc[dataset[\"category\"]==\"TEXT\",\"QueryLen\"] = dataset.loc[dataset[\"category\"]==\"TEXT\",\"value\"].str.len()\n",
    "dataset.loc[dataset[\"category\"]==\"TEXT\",\"QueryWords\"] = dataset.loc[dataset[\"category\"]==\"TEXT\",\"value\"].str.split().str.len()\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Work with text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.QT.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "stdf = dataset.loc[dataset.QT==\"Text\",'joint_text_embedding'].values\n",
    "stdf = np.stack(stdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedColnames = [\"f_\"+str(i) for i in range(stdf.shape[1])]\n",
    "dfEmbeds = pd.DataFrame(stdf, columns=embedColnames, index=dataset.loc[dataset.QT==\"Text\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jointDF = pd.concat([dataset.loc[dataset.QT==\"Text\"], dfEmbeds], axis=1)\n",
    "jointDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jointDF.task.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "def upper_tri_indexing(A):\n",
    "    m = A.shape[0]\n",
    "    r,c = np.triu_indices(m,1)\n",
    "    return A[r,c]\n",
    "\n",
    "def ILD(dataset, columns):\n",
    "    dt = dataset[columns].values\n",
    "    if len(dt)==0:\n",
    "        return (np.empty(shape=(0, 0)), 0)\n",
    "    distMatrix = pairwise_distances(dt,metric=\"cosine\")\n",
    "    #remove distances to self\n",
    "    distMatrix = upper_tri_indexing(distMatrix)\n",
    "    return (distMatrix,distMatrix.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_tri_indexing(np.array([[1,2,3],[4,5,6],[7,8,9]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does query distances differ for individual tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMats = {}\n",
    "for t in jointDF.task.unique():    \n",
    "    distMatrix, meanVal = ILD(jointDF.loc[jointDF[\"task\"]==t],embedColnames)\n",
    "    dMats[t] = distMatrix.ravel()\n",
    "    print (t, meanVal)\n",
    "dMats = pd.Series(dMats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textTasks = [i for i in jointDF.task.unique() if \"kis-t\" in i]\n",
    "visualTasks = [i for i in jointDF.task.unique() if ((\"kis-v-\" not in i)&(\"kis-v\" in i))]\n",
    "marineTasks = [i for i in jointDF.task.unique() if \"kis-v-\" in i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual tasks have smaller between-query distances than both visual ones\n",
    "- also marine tasks has slightly smaller distances than V3C1 visual ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "print(np.concatenate(dMats[textTasks].values).mean())\n",
    "print(np.concatenate(dMats[visualTasks].values).mean())\n",
    "print(np.concatenate(dMats[marineTasks].values).mean())\n",
    "print(ttest_ind(np.concatenate(dMats[textTasks].values),np.concatenate(dMats[visualTasks].values)))\n",
    "print(ttest_ind(np.concatenate(dMats[textTasks].values),np.concatenate(dMats[marineTasks].values)))\n",
    "print(ttest_ind(np.concatenate(dMats[marineTasks].values),np.concatenate(dMats[visualTasks].values)))\n",
    "\n",
    "txt = pd.DataFrame({\"v\": np.concatenate(dMats[textTasks].values)})\n",
    "txt[\"type\"]=\"Textual\"\n",
    "vis = pd.DataFrame({\"v\": np.concatenate(dMats[visualTasks].values)})\n",
    "vis[\"type\"]=\"Visual\"\n",
    "mar = pd.DataFrame({\"v\": np.concatenate(dMats[marineTasks].values)})\n",
    "mar[\"type\"]=\"Marine Visual\"\n",
    "dfPlot = pd.concat([txt,vis,mar])\n",
    "\n",
    "sns.boxenplot(y=dfPlot[\"v\"],x=dfPlot[\"type\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team-wise differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMats = {}\n",
    "for t in jointDF.task.unique():\n",
    "    for tm in jointDF.team.unique():\n",
    "        distMatrix, meanVal = ILD(jointDF.loc[((jointDF[\"task\"]==t)&(jointDF[\"team\"]==tm))],embedColnames)\n",
    "        dMats[(t,tm)] = distMatrix.ravel()\n",
    "        print (t, tm, meanVal)\n",
    "dMats = pd.Series(dMats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tm in jointDF.team.unique():\n",
    "    keys = list(np.broadcast(jointDF.task.unique(),tm))\n",
    "    print(tm, np.concatenate(dMats[keys].values).mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both vibro and VISIONE had more consistent per-task queries than CVHunter\n",
    "- comparison with other teams omitted due to missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ttest_ind(np.concatenate(dMats[list(np.broadcast(jointDF.task.unique(),\"vibro\"))].values),np.concatenate(dMats[list(np.broadcast(jointDF.task.unique(),\"CVHunter\"))].values)))\n",
    "print(ttest_ind(np.concatenate(dMats[list(np.broadcast(jointDF.task.unique(),\"VISIONE\"))].values),np.concatenate(dMats[list(np.broadcast(jointDF.task.unique(),\"CVHunter\"))].values)))\n",
    "print(ttest_ind(np.concatenate(dMats[list(np.broadcast(jointDF.task.unique(),\"vibro\"))].values),np.concatenate(dMats[list(np.broadcast(jointDF.task.unique(),\"VISIONE\"))].values)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of both users per team and task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jointDF.groupby([\"team\",\"user\"]).count()[\"task\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- removing verge as no distinction between users is available\n",
    "- several times, vitrivr-VR does not have any records from one of the users (candidate for removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jointDFNoVerge = jointDF.loc[jointDF.team != \"Verge\"]\n",
    "jointDF.shape,jointDFNoVerge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ILD_pair(dataset1, dataset2, columns):\n",
    "    dt1 = dataset1[columns].values\n",
    "    dt2 = dataset2[columns].values\n",
    "    if (len(dt1)==0)|(len(dt2)==0):\n",
    "        return (np.empty(shape=(0, 0)), 0)\n",
    "    distMatrix = pairwise_distances(dt1,dt2,metric=\"cosine\")\n",
    "    return (distMatrix.flatten(),distMatrix.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMats = {}\n",
    "for t in jointDFNoVerge.task.unique():\n",
    "    for tm in jointDFNoVerge.team.unique():\n",
    "        dt1 = jointDFNoVerge.loc[((jointDFNoVerge[\"task\"]==t)&(jointDFNoVerge[\"team\"]==tm)&(jointDFNoVerge[\"user\"]==0))]\n",
    "        dt2 = jointDFNoVerge.loc[((jointDFNoVerge[\"task\"]==t)&(jointDFNoVerge[\"team\"]==tm)&(jointDFNoVerge[\"user\"]==1))] \n",
    "        \n",
    "        distMatrix, meanVal = ILD_pair(dt1, dt2, embedColnames)\n",
    "        dMats[(t,tm)] = distMatrix.ravel()\n",
    "        print (t, tm, meanVal)\n",
    "dMats = pd.Series(dMats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tm in jointDFNoVerge.team.unique():\n",
    "    keys = list(np.broadcast(jointDFNoVerge.task.unique(),tm))\n",
    "    print(tm, np.concatenate(dMats[keys].values).mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- not so much different from the results of the overall distances (just a bit higher values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMats2 = {}\n",
    "for t in jointDFNoVerge.task.unique():\n",
    "    for tm in jointDFNoVerge.team.unique():\n",
    "        for u in jointDFNoVerge.user.unique():\n",
    "            distMatrix, meanVal = ILD(jointDFNoVerge.loc[((jointDFNoVerge[\"task\"]==t)&(jointDFNoVerge[\"team\"]==tm)&(jointDFNoVerge[\"user\"]==u))],embedColnames)\n",
    "            dMats2[(t,tm,u)] = distMatrix.ravel()\n",
    "            print (t, tm,u, meanVal)\n",
    "dMats2 = pd.Series(dMats2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- quite a few NaNs due to having only a single query per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tm in jointDFNoVerge.team.unique():\n",
    "    keys = list(np.broadcast(jointDFNoVerge.task.unique(),tm))\n",
    "    users = [0]*len(keys)+[1]*len(keys)\n",
    "    keys = [(keys[i%len(keys)][0],keys[i%len(keys)][1],val) for i,val in enumerate(users)]\n",
    "    print(tm, np.concatenate(dMats2[keys].values).mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Much smaller differences in within-user query distance as compared to between users (in the same team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tm in jointDFNoVerge.team.unique():\n",
    "    keys = list(np.broadcast(jointDFNoVerge.task.unique(),tm))\n",
    "    keys1 = keys\n",
    "    users = [0]*len(keys)+[1]*len(keys)\n",
    "    keys = [(keys[i%len(keys)][0],keys[i%len(keys)][1],val) for i,val in enumerate(users)]\n",
    "    \n",
    "    print(tm,ttest_ind(np.concatenate(dMats[keys1].values),np.concatenate(dMats2[keys].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differences in sequences of query reformulations\n",
    "- only users & tasks, where at least **4** text queries were made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = sortedData.loc[((sortedData.QueryRank <= 4)&(sortedData.MaxQueryRank >= 4))]\n",
    "#cannot be done for verge as only one user is present\n",
    "dt = dt.loc[dt.team != \"Verge\"]\n",
    "dt.columns,dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jointDF[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdf = dt.loc[dt.QT==\"Text\",'joint_text_embedding'].values\n",
    "stdf = np.stack(stdf)\n",
    "dfEmbeds = pd.DataFrame(stdf, columns=embedColnames, index=dt.loc[dt.QT==\"Text\"].index)\n",
    "seqDFEmbeds = pd.concat([dt.loc[dt.QT==\"Text\"], dfEmbeds], axis=1)\n",
    "seqDFEmbeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ILD_noRemove(dataset, columns):\n",
    "    dt = dataset[columns].values\n",
    "    if len(dt)==0:\n",
    "        return (np.empty(shape=(0, 0)), 0)\n",
    "    distMatrix = pairwise_distances(dt,metric=\"cosine\")\n",
    "    return (distMatrix,distMatrix.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dMats3 = {}\n",
    "for t in seqDFEmbeds.task.unique():\n",
    "    for tm in seqDFEmbeds.team.unique():\n",
    "        for u in seqDFEmbeds.user.unique():\n",
    "            dt = seqDFEmbeds.loc[((seqDFEmbeds[\"task\"]==t)&(seqDFEmbeds[\"team\"]==tm)&(seqDFEmbeds[\"user\"]==u))]\n",
    "            dt = dt.sort_values(\"QueryRank\")\n",
    "            #print(dt.QueryRank)\n",
    "            distMatrix, meanVal = ILD_noRemove(dt,embedColnames)\n",
    "            if len(distMatrix)>0:\n",
    "                dMats3[(t,tm,u)] = distMatrix\n",
    "            print (t, tm,u, meanVal)\n",
    "dMats3 = pd.Series(dMats3)\n",
    "sequentialResultsArray = np.stack(dMats3.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequentialResultsArray[:,0,:].mean(axis=0)#distances to first query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distances to subsequent queries\n",
    "print(\n",
    "    sequentialResultsArray[:,0,1].mean(),\n",
    "    sequentialResultsArray[:,1,2].mean(),\n",
    "    sequentialResultsArray[:,2,3].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([sequentialResultsArray[:,0,1],sequentialResultsArray[:,1,2],sequentialResultsArray[:,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## While the distance to the initial query rises over time (unsurprisingly), the step size between consecutive queries remain roughly the same and rather small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import ratio\n",
    "def LevenshteinNormDist(dataset, txtCol):\n",
    "    dt = dataset[txtCol].values\n",
    "    if len(dt)==0:\n",
    "        return (np.empty(shape=(0, 0)), 0)\n",
    "    distMatrix = np.zeros((len(dt),len(dt)))\n",
    "    for i,t1 in enumerate(dt):\n",
    "        for j,t2 in enumerate(dt):\n",
    "            distMatrix[i,j] = 1 - ratio(t1,t2)\n",
    "\n",
    "    return (distMatrix,distMatrix.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMats4 = {}\n",
    "for t in seqDFEmbeds.task.unique():\n",
    "    for tm in seqDFEmbeds.team.unique():\n",
    "        for u in seqDFEmbeds.user.unique():\n",
    "            dt = seqDFEmbeds.loc[((seqDFEmbeds[\"task\"]==t)&(seqDFEmbeds[\"team\"]==tm)&(seqDFEmbeds[\"user\"]==u))]\n",
    "            dt = dt.sort_values(\"QueryRank\")\n",
    "            #print(dt.QueryRank)\n",
    "            distMatrix, meanVal = LevenshteinNormDist(dt,\"value\")\n",
    "            if len(distMatrix)>0:\n",
    "                dMats4[(t,tm,u)] = distMatrix\n",
    "            print (t, tm,u, meanVal)\n",
    "dMats4 = pd.Series(dMats4)\n",
    "sequentialResultsLevensteinArray = np.stack(dMats4.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequentialResultsLevensteinArray[:,0,:].mean(axis=0)#distances to first query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distances to subsequent queries\n",
    "print(\n",
    "    sequentialResultsLevensteinArray[:,0,1].mean(),\n",
    "    sequentialResultsLevensteinArray[:,1,2].mean(),\n",
    "    sequentialResultsLevensteinArray[:,2,3].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(sequentialResultsLevensteinArray[:,0,1], sequentialResultsLevensteinArray[:,1,2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of Levenstein distance support those of embeds distance. It seems that subsequent changes are a bit smaller for later reformulations, but no stat sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differences in sequences of query reformulations\n",
    "- only users & tasks, where at least **3** text queries were made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = sortedData.loc[((sortedData.QueryRank <= 3)&(sortedData.MaxQueryRank >= 3))]\n",
    "#cannot be done for verge as only one user is present\n",
    "dt = dt.loc[dt.team != \"Verge\"]\n",
    "\n",
    "stdf = dt.loc[dt.QT==\"Text\",'joint_text_embedding'].values\n",
    "stdf = np.stack(stdf)\n",
    "dfEmbeds = pd.DataFrame(stdf, columns=embedColnames, index=dt.loc[dt.QT==\"Text\"].index)\n",
    "seqDFEmbeds = pd.concat([dt.loc[dt.QT==\"Text\"], dfEmbeds], axis=1)\n",
    "seqDFEmbeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMats3 = {}\n",
    "for t in seqDFEmbeds.task.unique():\n",
    "    for tm in seqDFEmbeds.team.unique():\n",
    "        for u in seqDFEmbeds.user.unique():\n",
    "            dt = seqDFEmbeds.loc[((seqDFEmbeds[\"task\"]==t)&(seqDFEmbeds[\"team\"]==tm)&(seqDFEmbeds[\"user\"]==u))]\n",
    "            dt = dt.sort_values(\"QueryRank\")\n",
    "            #print(dt.QueryRank)\n",
    "            distMatrix, meanVal = ILD_noRemove(dt,embedColnames)\n",
    "            if len(distMatrix)>0:\n",
    "                dMats3[(t,tm,u)] = distMatrix\n",
    "            print (t, tm,u, meanVal)\n",
    "dMats3 = pd.Series(dMats3)\n",
    "sequentialResultsArray = np.stack(dMats3.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequentialResultsArray[:,0,:].mean(axis=0)) #distances to first query\n",
    "\n",
    "print(#distances to subsequent queries\n",
    "    sequentialResultsArray[:,0,1].mean(),\n",
    "    sequentialResultsArray[:,1,2].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(sequentialResultsArray[:,0,1], sequentialResultsArray[:,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMats4 = {}\n",
    "for t in seqDFEmbeds.task.unique():\n",
    "    for tm in seqDFEmbeds.team.unique():\n",
    "        for u in seqDFEmbeds.user.unique():\n",
    "            dt = seqDFEmbeds.loc[((seqDFEmbeds[\"task\"]==t)&(seqDFEmbeds[\"team\"]==tm)&(seqDFEmbeds[\"user\"]==u))]\n",
    "            dt = dt.sort_values(\"QueryRank\")\n",
    "            #print(dt.QueryRank)\n",
    "            distMatrix, meanVal = LevenshteinNormDist(dt,\"value\")\n",
    "            if len(distMatrix)>0:\n",
    "                dMats4[(t,tm,u)] = distMatrix\n",
    "            print (t, tm,u, meanVal)\n",
    "dMats4 = pd.Series(dMats4)\n",
    "sequentialResultsLevensteinArray = np.stack(dMats4.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequentialResultsLevensteinArray[:,0,:].mean(axis=0)) #distances to first query\n",
    "\n",
    "print(#distances to subsequent queries\n",
    "    sequentialResultsLevensteinArray[:,0,1].mean(),\n",
    "    sequentialResultsLevensteinArray[:,1,2].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ttest_ind(sequentialResultsLevensteinArray[:,0,1], sequentialResultsLevensteinArray[:,1,2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differences in sequences of query reformulations\n",
    "- only users & tasks, where at least **5** text queries were made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = sortedData.loc[((sortedData.QueryRank <= 5)&(sortedData.MaxQueryRank >= 5))]\n",
    "#cannot be done for verge as only one user is present\n",
    "dt = dt.loc[dt.team != \"Verge\"]\n",
    "\n",
    "stdf = dt.loc[dt.QT==\"Text\",'joint_text_embedding'].values\n",
    "stdf = np.stack(stdf)\n",
    "dfEmbeds = pd.DataFrame(stdf, columns=embedColnames, index=dt.loc[dt.QT==\"Text\"].index)\n",
    "seqDFEmbeds = pd.concat([dt.loc[dt.QT==\"Text\"], dfEmbeds], axis=1)\n",
    "seqDFEmbeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMats3 = {}\n",
    "for t in seqDFEmbeds.task.unique():\n",
    "    for tm in seqDFEmbeds.team.unique():\n",
    "        for u in seqDFEmbeds.user.unique():\n",
    "            dt = seqDFEmbeds.loc[((seqDFEmbeds[\"task\"]==t)&(seqDFEmbeds[\"team\"]==tm)&(seqDFEmbeds[\"user\"]==u))]\n",
    "            dt = dt.sort_values(\"QueryRank\")\n",
    "            #print(dt.QueryRank)\n",
    "            distMatrix, meanVal = ILD_noRemove(dt,embedColnames)\n",
    "            if len(distMatrix)>0:\n",
    "                dMats3[(t,tm,u)] = distMatrix\n",
    "            print (t, tm,u, meanVal)\n",
    "dMats3 = pd.Series(dMats3)\n",
    "sequentialResultsArray = np.stack(dMats3.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequentialResultsArray[:,0,:].mean(axis=0)) #distances to first query\n",
    "\n",
    "print(#distances to subsequent queries\n",
    "    sequentialResultsArray[:,0,1].mean(),\n",
    "    sequentialResultsArray[:,1,2].mean(),\n",
    "    sequentialResultsArray[:,2,3].mean(),\n",
    "    sequentialResultsArray[:,3,4].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMats4 = {}\n",
    "for t in seqDFEmbeds.task.unique():\n",
    "    for tm in seqDFEmbeds.team.unique():\n",
    "        for u in seqDFEmbeds.user.unique():\n",
    "            dt = seqDFEmbeds.loc[((seqDFEmbeds[\"task\"]==t)&(seqDFEmbeds[\"team\"]==tm)&(seqDFEmbeds[\"user\"]==u))]\n",
    "            dt = dt.sort_values(\"QueryRank\")\n",
    "            #print(dt.QueryRank)\n",
    "            distMatrix, meanVal = LevenshteinNormDist(dt,\"value\")\n",
    "            if len(distMatrix)>0:\n",
    "                dMats4[(t,tm,u)] = distMatrix\n",
    "            print (t, tm,u, meanVal)\n",
    "dMats4 = pd.Series(dMats4)\n",
    "sequentialResultsLevensteinArray = np.stack(dMats4.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequentialResultsLevensteinArray[:,0,:].mean(axis=0)) #distances to first query\n",
    "\n",
    "print(#distances to subsequent queries\n",
    "    sequentialResultsLevensteinArray[:,0,1].mean(),\n",
    "    sequentialResultsLevensteinArray[:,1,2].mean(),\n",
    "    sequentialResultsLevensteinArray[:,2,3].mean(),\n",
    "    sequentialResultsLevensteinArray[:,3,4].mean()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differences in sequences of query reformulations\n",
    "- only users & tasks, where at least **4** text queries were made\n",
    "- selecting last 4 queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = sortedData.loc[((sortedData.DiffFromMaxQueryRank >= -3)&(sortedData.MaxQueryRank >= 4))]\n",
    "#cannot be done for verge as only one user is present\n",
    "dt = dt.loc[dt.team != \"Verge\"]\n",
    "\n",
    "stdf = dt.loc[dt.QT==\"Text\",'joint_text_embedding'].values\n",
    "stdf = np.stack(stdf)\n",
    "dfEmbeds = pd.DataFrame(stdf, columns=embedColnames, index=dt.loc[dt.QT==\"Text\"].index)\n",
    "seqDFEmbeds = pd.concat([dt.loc[dt.QT==\"Text\"], dfEmbeds], axis=1)\n",
    "seqDFEmbeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMats3 = {}\n",
    "for t in seqDFEmbeds.task.unique():\n",
    "    for tm in seqDFEmbeds.team.unique():\n",
    "        for u in seqDFEmbeds.user.unique():\n",
    "            dt = seqDFEmbeds.loc[((seqDFEmbeds[\"task\"]==t)&(seqDFEmbeds[\"team\"]==tm)&(seqDFEmbeds[\"user\"]==u))]\n",
    "            dt = dt.sort_values(\"QueryRank\")\n",
    "            #print(dt.QueryRank)\n",
    "            distMatrix, meanVal = ILD_noRemove(dt,embedColnames)\n",
    "            if len(distMatrix)>0:\n",
    "                dMats3[(t,tm,u)] = distMatrix\n",
    "            print (t, tm,u, meanVal)\n",
    "dMats3 = pd.Series(dMats3)\n",
    "sequentialResultsArray = np.stack(dMats3.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequentialResultsArray[:,2,:].mean(axis=0)) #distances to first query\n",
    "\n",
    "print(#distances to subsequent queries\n",
    "    sequentialResultsArray[:,0,1].mean(),\n",
    "    sequentialResultsArray[:,1,2].mean(),\n",
    "    sequentialResultsArray[:,2,3].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(sequentialResultsArray[:,0,1], sequentialResultsArray[:,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([sequentialResultsArray[:,0,1],sequentialResultsArray[:,1,2],sequentialResultsArray[:,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMats4 = {}\n",
    "for t in seqDFEmbeds.task.unique():\n",
    "    for tm in seqDFEmbeds.team.unique():\n",
    "        for u in seqDFEmbeds.user.unique():\n",
    "            dt = seqDFEmbeds.loc[((seqDFEmbeds[\"task\"]==t)&(seqDFEmbeds[\"team\"]==tm)&(seqDFEmbeds[\"user\"]==u))]\n",
    "            dt = dt.sort_values(\"QueryRank\")\n",
    "            #print(dt.QueryRank)\n",
    "            distMatrix, meanVal = LevenshteinNormDist(dt,\"value\")\n",
    "            if len(distMatrix)>0:\n",
    "                dMats4[(t,tm,u)] = distMatrix\n",
    "            print (t, tm,u, meanVal)\n",
    "dMats4 = pd.Series(dMats4)\n",
    "sequentialResultsLevensteinArray = np.stack(dMats4.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequentialResultsLevensteinArray[:,2,:].mean(axis=0)) #distances to first query\n",
    "\n",
    "print(#distances to subsequent queries\n",
    "    sequentialResultsLevensteinArray[:,0,1].mean(),\n",
    "    sequentialResultsLevensteinArray[:,1,2].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ttest_ind(sequentialResultsLevensteinArray[:,0,1], sequentialResultsLevensteinArray[:,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vbs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
